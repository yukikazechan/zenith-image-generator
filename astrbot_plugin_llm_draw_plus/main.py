import re
import random
from astrbot.api.all import *
from astrbot.api import logger
from astrbot.api.event import filter, AstrMessageEvent
from .ttp import generate_image, generate_video
from astrbot.api.message_components import *

@register("pic-gen", "å–µå–µ", "ä½¿ç”¨ç¡…åŸºæµåŠ¨api è®©llmå¸®ä½ ç”»å›¾", "0.0.2")
class MyPlugin(Star):
    def __init__(self, context: Context,config: dict):
        super().__init__(context)
        self.config = config # Save full config for dynamic access
        self.google_api_key = config.get("google_api_key")
        
        self.group_white_list = config.get("group_white_list", [])
        self.user_white_list = config.get("user_white_list", [])
        self.ignore_at_qq_list = config.get("ignore_at_qq_list", [])
        
        # API Configs
        self.openai_api_url = config.get("openai_api_url", "http://localhost:8317/v1/chat/completions")
        self.openai_api_tokens = config.get("openai_api_tokens", [])
        
        self.flow_api_url = config.get("flow_api_url", "http://localhost:8317/v1/chat/completions")
        self.flow_api_tokens = config.get("flow_api_tokens", [])
        
        # Model Names
        self.openai_model = config.get("openai_model", "gemini-2.5-flash-image-preview")
        self.openai_pro_model = config.get("openai_pro_model", "gemini-3-pro-image-preview")
        self.nano_model = config.get("nano_model", "gemini-2.5-flash-image-preview")
        self.nanopro_model = config.get("nanopro_model", "gemini-3.0-pro-image")
        self.flow_model = config.get("flow_model", "gemini-2.5-flash-image")
        self.flowpro_model = config.get("flowpro_model", "gemini-3.0-pro-image")
        
        # Round-Robin Counters
        self.openai_idx = 0
        self.flow_idx = 0

    def _check_permission(self, event: AstrMessageEvent) -> bool:
        if not self.group_white_list and not self.user_white_list:
            return True
        
        user_id = event.message_obj.sender.user_id
        if self.user_white_list and str(user_id) in [str(uid) for uid in self.user_white_list]:
            return True
            
        group_id = None
        if hasattr(event, 'message_obj') and event.message_obj:
            group_id = getattr(event.message_obj, 'group_id', None)
            
        if group_id and self.group_white_list:
            if str(group_id) in [str(gid) for gid in self.group_white_list]:
                return True

        return False
        
    def _get_next_api(self, api_type="openai"):
        """Get next API config (URL, Token) using Round-Robin for Tokens"""
        if api_type == "openai":
            if not self.openai_api_tokens: return self.openai_api_url, None
            token = self.openai_api_tokens[self.openai_idx % len(self.openai_api_tokens)]
            self.openai_idx += 1
            return self.openai_api_url, token
        elif api_type == "flow":
            if not self.flow_api_tokens: return self.flow_api_url, None
            token = self.flow_api_tokens[self.flow_idx % len(self.flow_api_tokens)]
            self.flow_idx += 1
            return self.flow_api_url, token
        return None, None
    async def _get_event_images(self, event: AstrMessageEvent, include_sender_avatar: bool = False) -> list[str]:
        """Extract images from event (message, quoted message, @mention avatar, and optional sender avatar)."""
        input_images_b64 = []
        
        # Helper to process a list of components
        async def process_chain(chain):
            for comp in chain:
                if isinstance(comp, Image):
                    try:
                        base64_data = await comp.convert_to_base64()
                        input_images_b64.append(base64_data)
                    except Exception as e:
                        logger.warning(f"Failed to convert image to base64: {e}")

        # 1. Current message images
        if hasattr(event, 'message_obj') and event.message_obj and hasattr(event.message_obj, 'message'):
            await process_chain(event.message_obj.message)
            
            # 2. Quoted message (Reply) images
            for comp in event.message_obj.message:
                if isinstance(comp, Reply) and comp.chain:
                    await process_chain(comp.chain)

        # 3. @Mention Avatars (Appended last)
        if hasattr(event, 'message_obj') and event.message_obj and hasattr(event.message_obj, 'message'):
            for comp in event.message_obj.message:
                if isinstance(comp, At):
                    try:
                        qq_id = str(comp.qq)
                        # Check ignore list (convert all to strings for comparison)
                        ignore_list = [str(x) for x in self.ignore_at_qq_list]
                        
                        if qq_id and qq_id not in ignore_list:
                            avatar_url = f"https://q1.qlogo.cn/g?b=qq&nk={qq_id}&s=640"
                            # Use Image.fromURL to download and convert
                            img_obj = Image.fromURL(avatar_url)
                            base64_data = await img_obj.convert_to_base64()
                            if base64_data:
                                input_images_b64.append(base64_data)
                    except Exception as e:
                        logger.warning(f"Failed to fetch avatar for {comp.qq}: {e}")
        
        # 4. Sender Avatar (if requested)
        if include_sender_avatar:
            try:
                sender_id = event.message_obj.sender.user_id
                if sender_id:
                     avatar_url = f"https://q1.qlogo.cn/g?b=qq&nk={sender_id}&s=640"
                     img_obj = Image.fromURL(avatar_url)
                     base64_data = await img_obj.convert_to_base64()
                     if base64_data:
                         input_images_b64.append(base64_data)
            except Exception as e:
                logger.warning(f"Failed to fetch sender avatar: {e}")

        return input_images_b64

    async def _generate_core(self, event, prompt, model_name, provider="flow", config_group=None, aspect_ratio=None, resolution=None, input_images_b64=None):
        """Core logic for image generation."""
        action = "æ”¹å›¾" if input_images_b64 else "ç”Ÿå›¾"
        
        # å‚æ•°è§£æ logic moved from _handle_gen_image
        if provider == "flow":
            # Flow2API: Only l/p
            if "--ar l" in prompt.lower():
                aspect_ratio = "landscape"
                prompt = re.sub(r'--ar\s+l', '', prompt, flags=re.IGNORECASE).strip()
            elif "--ar p" in prompt.lower():
                aspect_ratio = "portrait"
                prompt = re.sub(r'--ar\s+p', '', prompt, flags=re.IGNORECASE).strip()
            
        elif (provider == "openai" or provider == "official") and config_group:
            # Load specific config for this command group
            enable_ar = self.config.get(f"{config_group}_enable_ar", True)
            allowed_ars = self.config.get(f"{config_group}_allowed_ars", ["1:1","2:3","3:2","3:4","4:3","4:5","5:4","9:16","16:9","21:9"])
            enable_res = self.config.get(f"{config_group}_enable_res", False)
            allowed_res = self.config.get(f"{config_group}_allowed_res", ["1k", "2k", "4k"])

            # åªåœ¨ aspect_ratio æœªä¼ å…¥æ—¶æ‰ä» prompt è§£æ
            if enable_ar and not aspect_ratio:
                # Build regex from allowed_ars
                ar_pattern = "|".join([re.escape(ar) for ar in allowed_ars] + ["square", "landscape", "portrait"])
                ar_match = re.search(r'--ar\s+(' + ar_pattern + r')', prompt, re.IGNORECASE)
                
                if ar_match:
                    aspect_ratio = ar_match.group(1)
                    prompt = prompt.replace(ar_match.group(0), "").strip()
                
                # Support --ar l/p mapping for convenience if enabled
                if not aspect_ratio:
                    if "--ar l" in prompt.lower():
                        aspect_ratio = "16:9" # Default landscape
                        prompt = re.sub(r'--ar\s+l', '', prompt, flags=re.IGNORECASE).strip()
                    elif "--ar p" in prompt.lower():
                        aspect_ratio = "9:16" # Default portrait
                        prompt = re.sub(r'--ar\s+p', '', prompt, flags=re.IGNORECASE).strip()

            # åªåœ¨ resolution æœªä¼ å…¥æ—¶æ‰ä» prompt è§£æ
            if enable_res and not resolution:
                # Build regex from allowed_resolutions
                res_pattern = "|".join([re.escape(res) for res in allowed_res])
                res_match = re.search(r'--(' + res_pattern + r')', prompt, re.IGNORECASE)
                if res_match:
                    resolution = res_match.group(1).upper()
                    prompt = prompt.replace(res_match.group(0), "").strip()
        
        google_api_key = self.google_api_key

        # Get API URL/Token based on provider
        current_api_url = None
        current_api_token = None
        
        if provider == "openai":
            current_api_url, current_api_token = self._get_next_api("openai")
            if not current_api_url:
                return False, f"âŒ æœªé…ç½® OpenAI å…¼å®¹ API URL (openai_api_url)ã€‚", None, None
        elif provider == "flow":
            current_api_url, current_api_token = self._get_next_api("flow")
            if not current_api_url:
                return False, f"âŒ æœªé…ç½® Flow API URL (flow_api_url)ã€‚", None, None

        image_url, image_path, source = await generate_image(
            prompt,
            google_api_key=google_api_key,
            model=model_name,
            input_images_b64=input_images_b64 or [],
            flow_api_url=current_api_url,
            flow_api_token=current_api_token,
            provider=provider,
            aspect_ratio=aspect_ratio,
            resolution=resolution
        )
        
        if not image_url and not image_path:
            return False, f"{action}å¤±è´¥ï¼ŒæœªçŸ¥é”™è¯¯ã€‚", None, None
        if image_path and image_path.startswith("Error:"):
            return False, f"{action}å¤±è´¥: {image_path}", None, None

        chain = []
        if image_url:
            chain = [Image.fromURL(image_url)]
        elif image_path:
            chain = [Image.fromFileSystem(image_path)]
        else:
            return False, f"{action}å¤±è´¥ã€‚", None, None
            
        return True, "Success", chain, source

    async def _handle_gen_image(self, event, prompt, model_name, provider="flow", config_group=None):
        """Helper for image generation handling (Generator for Commands)"""
        if not self._check_permission(event):
            yield event.plain_result("âŒ æœªæˆæƒä½¿ç”¨ç”Ÿå›¾åŠŸèƒ½ã€‚")
            return

        # æå–å›¾ç‰‡ (Current + Quote)
        input_images_b64 = await self._get_event_images(event)
        
        action = "æ”¹å›¾" if input_images_b64 else "ç”Ÿå›¾"
        yield event.plain_result(f"æ­£åœ¨{action} ({provider} - {config_group if config_group else 'Flow'})... Prompt: {prompt}")

        success, msg, chain, source = await self._generate_core(event, prompt, model_name, provider, config_group, input_images_b64=input_images_b64)

        if not success:
            yield event.plain_result(msg)
            return
        
        if source:
            yield event.plain_result(f"âœ… ä½¿ç”¨æ¨¡å‹: {source}")
        yield event.chain_result(chain)

    @llm_tool(name="pic-gen")
    async def pic_gen(self, event: AstrMessageEvent, prompt: str = "", aspect_ratio: str = None, resolution: str = None, is_pro: bool = False, use_sender_avatar: bool = False) -> str:
        """
        é«˜è´¨é‡ç»˜å›¾**é¦–é€‰**ã€‚ä½¿ç”¨OpenAIå…¼å®¹å…è´¹æ¸ é“ï¼Œæ”¯æŒProæ¨¡å‹ã€å¤šå°ºå¯¸åŠ1k/2k/4kåˆ†è¾¨ç‡ã€‚å½“ç”¨æˆ·éœ€è¦é«˜è´¨é‡å›¾ç‰‡æˆ–æŒ‡å®šåˆ†è¾¨ç‡æ—¶ï¼Œå› å…¶å…è´¹ç‰¹æ€§ï¼Œä¼˜å…ˆä½¿ç”¨æ­¤å·¥å…·ã€‚
        
        Args:
            prompt (string): Image description.
            aspect_ratio (string): Optional aspect ratio (e.g. "16:9", "4:3", "1:1").
            resolution (string): Optional resolution (e.g. "1K", "2K", "4K").
            is_pro (bool): Set to True if user requests "high quality", "4k", "pro" model. Default True.
            use_sender_avatar (bool): Set to True if user refers to "me", "my avatar", "self", or "I" as the reference image.
        """
        model = self.openai_pro_model
        config_group = "openai_pro"

        # è‡ªåŠ¨æå–å›¾ç‰‡ (Current + Quote + Mention + Sender)
        input_images_b64 = await self._get_event_images(event, include_sender_avatar=use_sender_avatar)

        # ç›´æ¥ä¼ é€’ aspect_ratio å’Œ resolution å‚æ•°ï¼Œè€Œä¸æ˜¯è¿½åŠ åˆ° prompt
        success, msg, chain, source = await self._generate_core(
            event, prompt, model, provider="openai", config_group=config_group,
            aspect_ratio=aspect_ratio, resolution=resolution,
            input_images_b64=input_images_b64
        )
        if success:
            await event.send(event.chain_result(chain))
            ref_msg = f" using {len(input_images_b64)} reference image(s)" if input_images_b64 else ""
            return f"Image generated successfully{ref_msg}. Model: {source}. AR: {aspect_ratio}, Res: {resolution}. Prompt: {prompt}"
        else:
            return f"Image generation failed: {msg}"

    @llm_tool(name="nano-gen")
    async def nano_gen(self, event: AstrMessageEvent, prompt: str = "", aspect_ratio: str = None, resolution: str = None, is_pro: bool = False, use_sender_avatar: bool = False) -> str:
        """
        é«˜è´¨é‡ç»˜å›¾**å¤‡é€‰**ï¼ˆä»˜è´¹ï¼‰ã€‚ä½¿ç”¨å®˜æ–¹APIï¼Œæ”¯æŒProæ¨¡å‹ã€å¤šå°ºå¯¸åŠ1k/2k/4kåˆ†è¾¨ç‡ã€‚ä»…å½“pic-genå¤±è´¥æˆ–ç”¨æˆ·æ˜ç¡®è¦æ±‚ä½¿ç”¨å®˜æ–¹æ¸ é“/nanoæ—¶ä½¿ç”¨ã€‚
        
        Args:
            prompt (string): Image description.
            aspect_ratio (string): Optional aspect ratio (e.g. "16:9", "4:3", "1:1").
            resolution (string): Optional resolution (e.g. "1K", "2K", "4K"). Only effective if is_pro=True.
            is_pro (bool): Set to True if user requests "high quality", "4k", "pro" model. Default False.
            use_sender_avatar (bool): Set to True if user refers to "me", "my avatar", "self", or "I" as the reference image.
        """
        model = self.nanopro_model if is_pro else self.nano_model
        config_group = "nano_pro" if is_pro else "nano_normal"
        
        # è‡ªåŠ¨æå–å›¾ç‰‡
        input_images_b64 = await self._get_event_images(event, include_sender_avatar=use_sender_avatar)

        # ç›´æ¥ä¼ é€’ aspect_ratio å’Œ resolution å‚æ•°
        success, msg, chain, source = await self._generate_core(
            event, prompt, model, provider="official", config_group=config_group,
            aspect_ratio=aspect_ratio, resolution=resolution,
            input_images_b64=input_images_b64
        )
        if success:
            await event.send(event.chain_result(chain))
            ref_msg = f" using {len(input_images_b64)} reference image(s)" if input_images_b64 else ""
            return f"Image generated successfully{ref_msg}. Model: {source}. AR: {aspect_ratio}, Res: {resolution}. Prompt: {prompt}"
        else:
            return f"Image generation failed: {msg}"

    @llm_tool(name="flow-gen")
    async def flow_gen(self, event: AstrMessageEvent, prompt: str = "", aspect_ratio: str = "landscape", is_pro: bool = False, use_sender_avatar: bool = False) -> str:
        """
        å¿«é€Ÿ/ç®€å•ç»˜å›¾é¦–é€‰ã€‚è™½ç„¶æ”¯æŒProæ¨¡å‹ï¼ˆé«˜è´¨é‡ï¼‰ï¼Œä½†ä»…æ”¯æŒ1kåˆ†è¾¨ç‡åŠæ¨ªå±(16:9)/ç«–å±(9:16)ï¼Œæ— æ³•ç²¾ç»†è°ƒèŠ‚ã€‚é€Ÿåº¦å¿«ä¸”å…è´¹ã€‚å½“ç”¨æˆ·éœ€è¦å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡å›¾ç‰‡ä½†å¯¹åˆ†è¾¨ç‡/ç»†èŠ‚æ§åˆ¶æ— ä¸¥æ ¼è¦æ±‚æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨æ­¤å·¥å…·ã€‚
        
        Args:
            prompt (string): Description of the image.
            aspect_ratio (string): "landscape" (or "l") for horizontal, "portrait" (or "p") for vertical. Default is "landscape".
            is_pro (bool): Set to True if user requests "pro" model. Default False.
            use_sender_avatar (bool): Set to True if user refers to "me", "my avatar", "self", or "I" as the reference image.
        """
        full_prompt = prompt
        if aspect_ratio: full_prompt += f" --ar {aspect_ratio}"
        
        model = self.flowpro_model if is_pro else self.flow_model
        
        # è‡ªåŠ¨æå–å›¾ç‰‡
        input_images_b64 = await self._get_event_images(event, include_sender_avatar=use_sender_avatar)

        success, msg, chain, source = await self._generate_core(event, full_prompt, model, provider="flow", input_images_b64=input_images_b64)
        if success:
            await event.send(event.chain_result(chain))
            ref_msg = f" using {len(input_images_b64)} reference image(s)" if input_images_b64 else ""
            return f"Image generated successfully{ref_msg}. Model: {source}. Prompt: {full_prompt}"
        else:
            return f"Image generation failed: {msg}"

    @llm_tool(name="veo-gen")
    async def veo_gen(self, event: AstrMessageEvent, prompt: str = "", aspect_ratio: str = "landscape", use_sender_avatar: bool = False) -> str:
        """
        flowå¹³å°å…è´¹ç”Ÿæˆè§†é¢‘ï¼Œæ”¯æŒæ¨ªç«–å±ã€‚
        
        Args:
            prompt (string): Description of the video.
            aspect_ratio (string): "landscape" (or "l") for horizontal, "portrait" (or "p") for vertical. Default is "landscape".
            use_sender_avatar (bool): Set to True if user refers to "me", "my avatar", "self", or "I" as the reference image.
        """
        if not self._check_permission(event):
            await event.send(event.plain_result("âŒ æœªæˆæƒä½¿ç”¨ç”Ÿè§†é¢‘åŠŸèƒ½ã€‚"))
            return "Video generation failed: Unauthorized."
            
        flow_url, flow_token = self._get_next_api("flow")
        if not flow_url:
             await event.send(event.plain_result("âŒ æœªé…ç½® Flow API URL (flow_api_url)ã€‚"))
             return "Video generation failed: Missing API URL."

        # Normalize AR
        ar_param = "landscape"
        if aspect_ratio.lower() in ["p", "portrait"]: ar_param = "portrait"
        
        # Determine model (default to t2v)
        model = "veo_3_1_t2v_fast"
        
        # Check for input images (i2v) - Current + Quote + Mention + Sender
        input_images_b64 = await self._get_event_images(event, include_sender_avatar=use_sender_avatar)
        
        if len(input_images_b64) >= 1:
            model = "veo_3_1_i2v_s_fast_fl"

        await event.send(event.plain_result(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘ (Veo - {ar_param})... Prompt: {prompt}"))

        try:
            video_url, error_msg, source = await generate_video(
                prompt,
                model=model,
                input_images_b64=input_images_b64,
                flow_api_url=flow_url,
                flow_api_token=flow_token,
                aspect_ratio=ar_param
            )
            
            if not video_url:
                err = error_msg if error_msg else "æœªçŸ¥é”™è¯¯"
                await event.send(event.plain_result(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {err}"))
                return f"Video generation failed: {err}"
        except Exception as e:
            logger.error(f"Video generation exception: {e}")
            await event.send(event.plain_result(f"è§†é¢‘ç”Ÿæˆå‘ç”Ÿå¼‚å¸¸: {e}"))
            return f"Video generation failed: {e}"
            
        await event.send(event.chain_result([Video.fromURL(video_url)]))
        if source:
            await event.send(event.plain_result(f"âœ… ä½¿ç”¨æ¨¡å‹: {source}"))
            
        ref_msg = f" using {len(input_images_b64)} reference image(s)" if input_images_b64 else ""
        return f"Video generated successfully{ref_msg}. Model: {model}. Prompt: {prompt}"

    # @filter.command("ç”Ÿå›¾")
    # async def cmd_gen_image_openai(self, event: AstrMessageEvent, prompt: str = ""):
    #     """(OpenAI Compatible) ä½¿ç”¨é…ç½®çš„ openai_model ç”Ÿå›¾ã€‚"""
    #     texts = [comp.text for comp in event.message_obj.message if isinstance(comp, Plain)]
    #     full_text = "".join(texts).strip()
    #     if "/ç”Ÿå›¾" in full_text: prompt = full_text.split("/ç”Ÿå›¾", 1)[1].strip()
    #     elif "ç”Ÿå›¾" in full_text: prompt = full_text.split("ç”Ÿå›¾", 1)[1].strip()
    #     
    #     async for result in self._handle_gen_image(event, prompt, self.openai_model, provider="openai", config_group="openai_normal"):
    #         yield result

    @filter.command("ç”Ÿå›¾pro")
    async def cmd_gen_image_openai_pro(self, event: AstrMessageEvent, prompt: str = ""):
        """(OpenAI Compatible) ä½¿ç”¨é…ç½®çš„ openai_pro_model ç”Ÿå›¾ã€‚"""
        texts = [comp.text for comp in event.message_obj.message if isinstance(comp, Plain)]
        full_text = "".join(texts).strip()
        if "/ç”Ÿå›¾pro" in full_text: prompt = full_text.split("/ç”Ÿå›¾pro", 1)[1].strip()
        elif "ç”Ÿå›¾pro" in full_text: prompt = full_text.split("ç”Ÿå›¾pro", 1)[1].strip()

        async for result in self._handle_gen_image(event, prompt, self.openai_pro_model, provider="openai", config_group="openai_pro"):
            yield result

    @filter.command("nano")
    async def cmd_gen_image_nano(self, event: AstrMessageEvent, prompt: str = ""):
        """(å®˜æ–¹API) ä½¿ç”¨é…ç½®çš„ nano_model ç”Ÿå›¾ã€‚"""
        texts = [comp.text for comp in event.message_obj.message if isinstance(comp, Plain)]
        full_text = "".join(texts).strip()
        if "/nano" in full_text: prompt = full_text.split("/nano", 1)[1].strip()
        elif "nano" in full_text: prompt = full_text.split("nano", 1)[1].strip()

        async for result in self._handle_gen_image(event, prompt, self.nano_model, provider="official", config_group="nano_normal"):
            yield result

    @filter.command("nanopro")
    async def cmd_gen_image_nanopro(self, event: AstrMessageEvent, prompt: str = ""):
        """(å®˜æ–¹API) ä½¿ç”¨é…ç½®çš„ nanopro_model ç”Ÿå›¾ã€‚"""
        texts = [comp.text for comp in event.message_obj.message if isinstance(comp, Plain)]
        full_text = "".join(texts).strip()
        if "/nanopro" in full_text: prompt = full_text.split("/nanopro", 1)[1].strip()
        elif "nanopro" in full_text: prompt = full_text.split("nanopro", 1)[1].strip()

        async for result in self._handle_gen_image(event, prompt, self.nanopro_model, provider="official", config_group="nano_pro"):
            yield result

    @filter.command("flow")
    async def cmd_gen_image_flow(self, event: AstrMessageEvent, prompt: str = ""):
        """(Flow2API) ä½¿ç”¨é…ç½®çš„ flow_model ç”Ÿå›¾ã€‚å‚æ•°: --ar l (æ¨ªå±) / --ar p (ç«–å±)ã€‚"""
        texts = [comp.text for comp in event.message_obj.message if isinstance(comp, Plain)]
        full_text = "".join(texts).strip()
        if "/flow" in full_text: prompt = full_text.split("/flow", 1)[1].strip()
        elif "flow" in full_text: prompt = full_text.split("flow", 1)[1].strip()
        
        async for result in self._handle_gen_image(event, prompt, self.flow_model, provider="flow"):
            yield result

    @filter.command("flowpro")
    async def cmd_gen_image_flow_pro(self, event: AstrMessageEvent, prompt: str = ""):
        """(Flow2API) ä½¿ç”¨é…ç½®çš„ flowpro_model ç”Ÿå›¾ã€‚å‚æ•°: --ar l (æ¨ªå±) / --ar p (ç«–å±)ã€‚"""
        texts = [comp.text for comp in event.message_obj.message if isinstance(comp, Plain)]
        full_text = "".join(texts).strip()
        if "/flowpro" in full_text: prompt = full_text.split("/flowpro", 1)[1].strip()
        elif "flowpro" in full_text: prompt = full_text.split("flowpro", 1)[1].strip()
        
        async for result in self._handle_gen_image(event, prompt, self.flowpro_model, provider="flow"):
            yield result

    @filter.command("ç”Ÿè§†é¢‘")
    async def cmd_gen_video(self, event: AstrMessageEvent, prompt: str = ""):
        """ä½¿ç”¨ Flow2API ç”Ÿæˆè§†é¢‘ã€‚ç”¨æ³•ï¼š/ç”Ÿè§†é¢‘ <æç¤ºè¯>ã€‚æ”¯æŒé™„å¸¦å›¾ç‰‡ä½œä¸ºé¦–å°¾å¸§ã€‚"""
        if not self._check_permission(event):
            yield event.plain_result("âŒ æœªæˆæƒä½¿ç”¨ç”Ÿè§†é¢‘åŠŸèƒ½ã€‚")
            return
            
        # Use Flow APIs for video
        flow_url, flow_token = self._get_next_api("flow")
        if not flow_url:
             yield event.plain_result("âŒ æœªé…ç½® Flow API URL (flow_api_url)ï¼Œæ— æ³•ä½¿ç”¨ç”Ÿè§†é¢‘åŠŸèƒ½ã€‚")
             return

        # æ‰‹åŠ¨æå–å®Œæ•´ prompt
        texts = []
        for comp in event.message_obj.message:
            if isinstance(comp, Plain):
                texts.append(comp.text)
        
        full_text = "".join(texts).strip()
        
        if "/ç”Ÿè§†é¢‘" in full_text:
            prompt = full_text.split("/ç”Ÿè§†é¢‘", 1)[1].strip()
        elif "ç”Ÿè§†é¢‘" in full_text:
            prompt = full_text.split("ç”Ÿè§†é¢‘", 1)[1].strip()
            
            prompt = full_text.split("ç”Ÿè§†é¢‘", 1)[1].strip()
            
        # æå–å›¾ç‰‡ - Current + Quote
        input_images_b64 = await self._get_event_images(event)

        # Flow2API Video AR: --ar l / p
        aspect_ratio = "landscape" # Default
        
        # Enhanced AR parsing
        ar_match_l = re.search(r'--ar\s+(l|landscape)', prompt, re.IGNORECASE)
        ar_match_p = re.search(r'--ar\s+(p|portrait)', prompt, re.IGNORECASE)
        
        if ar_match_p:
            aspect_ratio = "portrait"
            prompt = prompt.replace(ar_match_p.group(0), "").strip()
        elif ar_match_l:
            aspect_ratio = "landscape"
            prompt = prompt.replace(ar_match_l.group(0), "").strip()

        # ç¡®å®šæ¨¡å‹
        model = "veo_3_1_t2v_fast" # é»˜è®¤æ–‡ç”Ÿè§†é¢‘
        if len(input_images_b64) == 2:
            model = "veo_3_1_i2v_s_fast_fl" # é¦–å°¾å¸§
            yield event.plain_result(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘ (é¦–å°¾å¸§æ¨¡å¼ - {aspect_ratio})... Prompt: {prompt}")
        elif len(input_images_b64) == 1:
            model = "veo_3_1_i2v_s_fast_fl" # å›¾ç”Ÿè§†é¢‘ (i2v)
            yield event.plain_result(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘ (å›¾ç”Ÿè§†é¢‘æ¨¡å¼ - {aspect_ratio})... Prompt: {prompt}")
        else:
            yield event.plain_result(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘ (æ–‡ç”Ÿè§†é¢‘æ¨¡å¼ - {aspect_ratio})... Prompt: {prompt}")

        try:
            video_url, error_msg, source = await generate_video(
                prompt,
                model=model,
                input_images_b64=input_images_b64,
                flow_api_url=flow_url,
                flow_api_token=flow_token,
                aspect_ratio=aspect_ratio
            )
            
            if not video_url:
                err = error_msg if error_msg else "æœªçŸ¥é”™è¯¯"
                yield event.plain_result(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {err}")
                return
        except Exception as e:
            logger.error(f"Video generation exception: {e}")
            yield event.plain_result(f"è§†é¢‘ç”Ÿæˆå‘ç”Ÿå¼‚å¸¸: {e}")
            return
            
        yield event.chain_result([Video.fromURL(video_url)])
        if source:
            yield event.plain_result(f"âœ… ä½¿ç”¨æ¨¡å‹: {source}")

    @filter.command("ç”Ÿå›¾help")
    async def cmd_image_help(self, event: AstrMessageEvent):
        """æ˜¾ç¤ºç”Ÿå›¾æ’ä»¶çš„å¸®åŠ©ä¿¡æ¯"""
        # Helper to format list or show "ä¸æ”¯æŒ"
        def fmt(enabled, items):
            return ', '.join(items) if enabled else 'ä¸æ”¯æŒ'

        help_msg = (
            "ğŸ¨ **ç”Ÿå›¾æ’ä»¶å¸®åŠ©** ğŸ¨\n\n"
            "**è‡ªç„¶è¯­è¨€ç”Ÿå›¾ (æ¨è):**\n"
            "ç›´æ¥å‘é€ \"å¸®æˆ‘ç”»ä¸€å¼ ...\" æˆ– \"ç”»ä¸ª...\" å³å¯ï¼Œä¼šè‡ªåŠ¨è°ƒç”¨ç”»å›¾å·¥å…·ã€‚\n"
            "å½“å‰å¯ç”¨å·¥å…·:\n"
            "- **pic-gen**: é€šè¿‡åé‡åŠ›è°ƒç”¨å¤§é¦™è•‰ï¼Œæ”¯æŒæ¯”ä¾‹å’Œåˆ†è¾¨ç‡\n"
            "- **nano-gen**: é€šè¿‡è°·æ­Œä»˜è´¹APIè°ƒç”¨å¤§å°é¦™è•‰ï¼Œæ”¯æŒæ¯”ä¾‹å’Œåˆ†è¾¨ç‡\n"
            "- **flow-gen**: é€šè¿‡è°·æ­ŒFlowå¹³å°å…è´¹è°ƒç”¨å¤§å°é¦™è•‰ï¼Œå³æ”¯æŒ1kæ¨ªç«–å±\n"
            "- **veo-gen**: é€šè¿‡è°·æ­ŒFlowå¹³å°å…è´¹ç”Ÿæˆè§†é¢‘ï¼Œæ”¯æŒæ¨ªç«–å±\n"
            "ç¤ºä¾‹: \"å¸®æˆ‘ç”»ä¸€å¼ èµ›åšæœ‹å…‹é£æ ¼çš„çŒ«\"\n\n"
            "**OpenAI å…¼å®¹æ¨¡å¼:**\n"
            f"- `/ç”Ÿå›¾ <æç¤ºè¯>`: (æš‚åœä½¿ç”¨) å›  Flash æ¨¡å‹å¤±æ•ˆæš‚æ—¶åœç”¨ï¼Œæš‚æ—¶åªèƒ½ä½¿ç”¨ /ç”Ÿå›¾pro\n"
            f"- `/ç”Ÿå›¾pro <æç¤ºè¯>`: {self.openai_pro_model}\n"
            f"  æ”¯æŒæ¯”ä¾‹: {fmt(self.config.get('openai_pro_enable_ar'), self.config.get('openai_pro_allowed_ars'))}\n"
            f"  æ”¯æŒåˆ†è¾¨ç‡: {fmt(self.config.get('openai_pro_enable_res'), self.config.get('openai_pro_allowed_res'))}\n"
            f"  å‚æ•°ç¤ºä¾‹: --ar 16:9 --4k\n\n"
            "**å®˜æ–¹ API æ¨¡å¼:**\n"
            f"- `/nano <æç¤ºè¯>`: {self.nano_model}\n"
            f"  æ”¯æŒæ¯”ä¾‹: {fmt(self.config.get('nano_normal_enable_ar'), self.config.get('nano_normal_allowed_ars'))}\n"
            f"  æ”¯æŒåˆ†è¾¨ç‡: {fmt(self.config.get('nano_normal_enable_res'), self.config.get('nano_normal_allowed_res'))}\n"
            f"- `/nanopro <æç¤ºè¯>`: {self.nanopro_model}\n"
            f"  æ”¯æŒæ¯”ä¾‹: {fmt(self.config.get('nano_pro_enable_ar'), self.config.get('nano_pro_allowed_ars'))}\n"
            f"  æ”¯æŒåˆ†è¾¨ç‡: {fmt(self.config.get('nano_pro_enable_res'), self.config.get('nano_pro_allowed_res'))}\n\n"
            "**Flow æ¨¡å¼:**\n"
            f"- `/flow <æç¤ºè¯>`: {self.flow_model}\n"
            f"- `/flowpro <æç¤ºè¯>`: {self.flowpro_model}\n"
            "  å‚æ•°: `--ar l` (æ¨ªå±), `--ar p` (ç«–å±)\n\n"
            "**è§†é¢‘ç”Ÿæˆ:**\n"
            "- `/ç”Ÿè§†é¢‘ <æç¤ºè¯>`: Flow2API è§†é¢‘ç”Ÿæˆ\n"
            "  å‚æ•°: `--ar l` (æ¨ªå±), `--ar p` (ç«–å±)\n"
            "  æ”¯æŒé™„å¸¦å›¾ç‰‡è¿›è¡Œå›¾ç”Ÿè§†é¢‘æˆ–é¦–å°¾å¸§ç”Ÿæˆã€‚"
        )
        yield event.plain_result(help_msg)